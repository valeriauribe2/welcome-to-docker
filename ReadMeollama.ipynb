{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open Terminal / Command Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /path/to/your/directory\n",
    "git clone https://github.com/octocat/Hello-World.git\n",
    "cd Hello-World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Install Ollama + ollama3 + webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/ollama/ollama.git\n",
    "git clone https://github.com/ollama/ollama3.git\n",
    "git clone https://github.com/ollama/webui.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Install Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ollama\n",
    "pip install -r requirements.txt\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Install Ollama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../ollama3\n",
    "pip install -r requirements.txt\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Install WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../webui\n",
    "npm install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Run WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npm start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama --version\n",
    "ollama3 --version\n",
    "WebUI: Ensure the web interface is accessible via your browser at http://localhost:3000 or the port specified during installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// If you are using docker:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dockerfile for Ollama.\n",
    "2. Create folder for ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd GitHub/welcome-to-docker \n",
    "mkdir ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create Dockerfile using Terminal command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch Dockerfile\n",
    "nano Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add Dockerfile Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama/Dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . /app\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"ollama.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and close by pressing CTRL+X, Y and then Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dockerfile for Ollama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama3/Dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . /app\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"ollama3.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dockerfile for WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webui/Dockerfile\n",
    "FROM node:14\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . /app\n",
    "\n",
    "RUN npm install\n",
    "\n",
    "ENTRYPOINT [\"npm\", \"start\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Docker Compose File on GitHub/welcome-to-docker root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  ollama:\n",
    "    build:\n",
    "      context: ./ollama\n",
    "    container_name: ollama\n",
    "    volumes:\n",
    "      - ./ollama:/app\n",
    "    networks:\n",
    "      - ollama-network\n",
    "\n",
    "  ollama3:\n",
    "    build:\n",
    "      context: ./ollama3\n",
    "    container_name: ollama3\n",
    "    volumes:\n",
    "      - ./ollama3:/app\n",
    "    networks:\n",
    "      - ollama-network\n",
    "\n",
    "  webui:\n",
    "    build:\n",
    "      context: ./webui\n",
    "    container_name: webui\n",
    "    volumes:\n",
    "      - ./webui:/app\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    networks:\n",
    "      - ollama-network\n",
    "\n",
    "networks:\n",
    "  ollama-network:\n",
    "    driver: bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and Run Containers\n",
    "\t1.\tNavigate to the root directory where your docker-compose.yml file is located.\n",
    "\t2.\tBuild and start the containers using Docker Compose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask==2.0.1\n",
    "requests==2.25.1\n",
    "numpy==1.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Users/valeriauribe/GitHub/welcome-to-docker/\n",
    "├── docker-compose.yml\n",
    "├── ollama/\n",
    "│   ├── Dockerfile\n",
    "│   ├── requirements.txt\n",
    "│   ├── ollama.py\n",
    "│   └── ... (other project files)\n",
    "├── ollama3/\n",
    "│   ├── Dockerfile\n",
    "│   ├── requirements.txt\n",
    "│   ├── ollama3.py\n",
    "│   └── ... (other project files)\n",
    "└── webui/\n",
    "    ├── Dockerfile\n",
    "    ├── package.json\n",
    "    ├── ... (other project files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker-compose up --build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Ollama\n",
    "- Create requirements.rxr\n",
    "- Create app.py\n",
    "- Create dockfile\n",
    "- Create .yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Ollama>Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM python:3.9-slim\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install flask\n",
    "EXPOSE 80\n",
    "CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ollama > app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from urllib.parse import quote as url_quote\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "    return 'Hello, World!'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Ollama > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask==2.0.1\n",
    "Werkzeug==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Navigate\n",
    "2. Build\n",
    "3. Run the dock container\n",
    "4. Verify the running container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/valeriauribe/GitHub/welcome-to-docker/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker build -t ollama-image ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run -d -p 8080:80 --name ollama-container ollama-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://localhost:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see \"Hello World!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create now for llama3 and webui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Users/valeriauribe/GitHub/welcome-to-docker/\n",
    "├── docker-compose.yml\n",
    "├── ollama/\n",
    "│   ├── Dockerfile\n",
    "│   ├── requirements.txt\n",
    "│   ├── ollama.py\n",
    "├── llama3/\n",
    "│   ├── Dockerfile\n",
    "│   ├── requirements.txt\n",
    "│   ├── llama3.py\n",
    "└── webui/\n",
    "    ├── Dockerfile\n",
    "    ├── package.json\n",
    "    ├── public/\n",
    "    │   ├── index.html\n",
    "    ├── src/\n",
    "    │   ├── index.js\n",
    "    │   ├── App.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great to hear that it worked! Here's a summary of what you achieved:\n",
    "\n",
    "1. **Set up and configured three services:**\n",
    "   - **ollama** with Python Flask application.\n",
    "   - **llama3** with Python Flask application.\n",
    "   - **webui** with a React application.\n",
    "\n",
    "2. **Created and configured Dockerfiles for each service.**\n",
    "\n",
    "3. **Created and configured the `docker-compose.yml` file to manage multi-container applications.**\n",
    "\n",
    "4. **Ensured the correct directory structure and necessary files for the React application.**\n",
    "\n",
    "5. **Rebuilt and ran the Docker containers successfully.**\n",
    "\n",
    "### Recap of Important Files and Configuration\n",
    "\n",
    "#### Directory Structure\n",
    "\n",
    "```\n",
    "/Users/valeriauribe/GitHub/welcome-to-docker/\n",
    "├── docker-compose.yml\n",
    "├── ollama/\n",
    "│   ├── Dockerfile\n",
    "│   ├── requirements.txt\n",
    "│   ├── ollama.py\n",
    "├── llama3/\n",
    "│   ├── Dockerfile\n",
    "│   ├── requirements.txt\n",
    "│   ├── llama3.py\n",
    "└── webui/\n",
    "    ├── Dockerfile\n",
    "    ├── package.json\n",
    "    ├── public/\n",
    "    │   ├── index.html\n",
    "    ├── src/\n",
    "    │   ├── index.js\n",
    "    │   ├── App.js\n",
    "```\n",
    "\n",
    "#### `docker-compose.yml`\n",
    "\n",
    "```yaml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  ollama:\n",
    "    build:\n",
    "      context: ./ollama\n",
    "    container_name: ollama\n",
    "    ports:\n",
    "      - \"8080:80\"\n",
    "    networks:\n",
    "      - ollama-network\n",
    "\n",
    "  llama3:\n",
    "    build:\n",
    "      context: ./llama3\n",
    "    container_name: llama3\n",
    "    ports:\n",
    "      - \"8081:80\"\n",
    "    networks:\n",
    "      - ollama-network\n",
    "\n",
    "  webui:\n",
    "    build:\n",
    "      context: ./webui\n",
    "    container_name: webui\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    networks:\n",
    "      - ollama-network\n",
    "\n",
    "networks:\n",
    "  ollama-network:\n",
    "    driver: bridge\n",
    "```\n",
    "\n",
    "### Accessing Your Services\n",
    "\n",
    "- **ollama**: http://localhost:8080\n",
    "- **llama3**: http://localhost:8081\n",
    "- **webui**: http://localhost:3000\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Now that you have your multi-container application running, you can:\n",
    "\n",
    "1. **Develop and test** your applications within their respective environments.\n",
    "2. **Deploy** your Docker Compose setup to a production environment.\n",
    "3. **Scale** your services as needed using Docker Compose commands.\n",
    "\n",
    "If you have any further questions or need additional assistance, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing Your Services\n",
    "\n",
    "\t•\tollama: http://localhost:8080\n",
    "\t•\tllama3: http://localhost:8081\n",
    "\t•\twebui: http://localhost:3000\n",
    "\n",
    "Next Steps\n",
    "\n",
    "Now that you have your multi-container application running, you can:\n",
    "\n",
    "\t1.\tDevelop and test your applications within their respective environments.\n",
    "\t2.\tDeploy your Docker Compose setup to a production environment.\n",
    "\t3.\tScale your services as needed using Docker Compose commands.\n",
    "\n",
    "If you have any further questions or need additional assistance, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd/GitHub/welcome-to-docker/Fabric % yt --transcript https://www.youtube.com/watch?v=m5VVqm43j7Y | fabric --model llama3:latest -sp extract_wisdom\n",
    "zsh: no matches found: https://www.youtube.com/watch?v=m5VVqm43j7Y"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
